{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 2 : Bayes risk with absolute loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the exponential distribution to try split the two estimators for the l1 and l2 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rl1(fl2): 0.7351313528651133\n",
      "Rl1(fl1): 0.6924682246745301\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# number of data points\n",
    "n = 1000000\n",
    "\n",
    "# X is uniformly distributed between 0 and 1\n",
    "X = np.random.uniform(0, 1, n)\n",
    "\n",
    "# Y|x follows an exponential distribution with rate parameter 1\n",
    "Y = np.random.exponential(1, n)\n",
    "\n",
    "# calculate conditional mean (fl2)\n",
    "fl2 = np.mean(Y)\n",
    "\n",
    "# calculate conditional median (fl1)\n",
    "fl1 = np.median(Y)\n",
    "\n",
    "# compute Rl1 for fl2\n",
    "Rl1_fl2 = np.mean(np.abs(Y - fl2))\n",
    "\n",
    "# compute Rl1 for fl1\n",
    "Rl1_fl1 = np.mean(np.abs(Y - fl1))\n",
    "\n",
    "print('Rl1(fl2):', Rl1_fl2)\n",
    "print('Rl1(fl1):', Rl1_fl1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus for this setup we have Rl1(fl1) < Rl1(fl2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2:\n",
    "\n",
    "To find the Bayes predictor under the L1 loss, we want to minimize the expected absolute deviation of $Y$ from a constant $z$ given $X = x$. Mathematically, we want to minimize the following expression:\n",
    "\n",
    "$$g(z) = \\int_{-\\infty}^{\\infty} |y - z| \\cdot p_{Y|X=x}(y) \\, dy$$\n",
    "\n",
    "where $p_{Y|X=x}(y)$ is the conditional density function of $Y$ given $X = x$.\n",
    "\n",
    "To minimize $g(z)$, we differentiate it and set the derivative equal to zero:\n",
    "\n",
    "$$\\frac{d}{dz} \\left(\\int_{-\\infty}^{\\infty} |y - z| \\cdot p_{Y|X=x}(y) \\, dy\\right) = 0$$\n",
    "\n",
    "Let's consider two cases:\n",
    "\n",
    "1. $z < y$: In this case, $|y - z| = y - z$, and the derivative with respect to $z$ is $-\\int_{z}^{\\infty} p_{Y|X=x}(y) \\, dy$.\n",
    "\n",
    "2. $z > y$: In this case, $|y - z| = z - y$, and the derivative with respect to $z$ is $\\int_{-\\infty}^{z} p_{Y|X=x}(y) \\, dy$.\n",
    "\n",
    "Setting the derivative equal to zero for both cases, we get:\n",
    "\n",
    "$$-\\int_{z}^{\\infty} p_{Y|X=x}(y) \\, dy + \\int_{-\\infty}^{z} p_{Y|X=x}(y) \\, dy = 0$$\n",
    "\n",
    "Simplifying the equation gives:\n",
    "\n",
    "$$\\int_{-\\infty}^{z} p_{Y|X=x}(y) \\, dy = \\int_{z}^{\\infty} p_{Y|X=x}(y) \\, dy$$\n",
    "\n",
    "This equation essentially states that the area under the density function curve from $-\\infty$ to $z$ is equal to the area from $z$ to $\\infty$. Geometrically, this means that $z$ is the value that divides the conditional distribution of $Y$ into two equal halves.\n",
    "\n",
    "Therefore, if this extremum is a minimum the Bayes predictor under the L1 loss is the median of the conditional distribution of $Y$ given $X = x$:\n",
    "\n",
    "$$f^*_{l1}(x) = \\text{median}(Y|X = x)$$\n",
    "\n",
    "\n",
    "To determine whether the obtained solution is a minimum, we need to examine the second derivative of the function $g(z)$.\n",
    "\n",
    "To find the second derivative, we differentiate $g(z)$ twice :\n",
    "\n",
    "$$g''(z) = \\frac{d^2}{dz^2} \\left( \\int_{-\\infty}^{\\infty} |y - z| \\cdot p_{Y|X=x}(y) \\, dy \\right)$$\n",
    "\n",
    "Let's consider two cases:\n",
    "\n",
    "1. $z < y$: In this case, $|y - z| = y - z$, and the second derivative with respect to $z$ is $\\int_{z}^{\\infty} p_{Y|X=x}(y) \\, dy$.\n",
    "\n",
    "2. $z > y$: In this case, $|y - z| = z - y$, and the second derivative with respect to $z$ is $-\\int_{-\\infty}^{z} p_{Y|X=x}(y) \\, dy$.\n",
    "\n",
    "Adding the second derivatives from both cases, we get:\n",
    "\n",
    "$$g''(z) = \\int_{-\\infty}^{z} p_{Y|X=x}(y) \\, dy - \\int_{z}^{\\infty} p_{Y|X=x}(y) \\, dy$$\n",
    "\n",
    "Simplifying, we have:\n",
    "\n",
    "$$g''(z) = \\int_{-\\infty}^{z} p_{Y|X=x}(y) \\, dy + \\int_{-\\infty}^{z} p_{Y|X=x}(y) \\, dy$$\n",
    "\n",
    "Combining the two integrals, we obtain:\n",
    "\n",
    "$$g''(z) = 2\\int_{-\\infty}^{z} p_{Y|X=x}(y) \\, dy$$\n",
    "\n",
    "Since $p_{Y|X=x}(y)$ is a probability density function, it is non-negative for all $y$. Therefore, the integral $\\int_{-\\infty}^{z} p_{Y|X=x}(y) \\, dy$ is also non-negative.\n",
    "\n",
    "Thus, we have shown that the second derivative $g''(z)$ is non-negative for all $z$. This implies that the obtained solution, which corresponds to the median, is a minimum for the function $g(z)$.\n",
    "\n",
    "Therefore, the Bayes predictor under the L1 loss, $f^*_{l1}(x)$, is indeed the minimum of the expected absolute deviation and is represented by the median of the conditional distribution of $Y$ given $X = x$.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
